{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f3f16e5",
   "metadata": {},
   "source": [
    "Автор: Лещенко Сергей \\\n",
    "Год: 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f25a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f64af5",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a46ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_train_path = \"./text_leshchenko.Result.xml\"\n",
    "output_dir     = \"./Allophone-model/\"\n",
    "\n",
    "# model_name   = \"ai-forever/ruT5-base\" - базовая модель для дообучения\n",
    "model_name     = \"./Allophone-model/\"  # Дообученная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273f9736",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(XML_train_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "data = []\n",
    "\n",
    "for sentence in root.findall(\".//sentence\"):\n",
    "    for word in sentence.findall(\".//word\"):\n",
    "\n",
    "        # Исходное слово: (тег <word> → атрибут original)\n",
    "        original = word.get(\"original\")\n",
    "\n",
    "        letters = []\n",
    "        allophones = []\n",
    "\n",
    "        # Собираем буквы и аллофоны\n",
    "        for elem in word:\n",
    "            if elem.tag == \"letter\":\n",
    "                char = elem.get(\"char\")\n",
    "                if char:\n",
    "                    letters.append(char)\n",
    "\n",
    "            elif elem.tag == \"allophone\":\n",
    "                ph = elem.get(\"ph\")\n",
    "                if ph:\n",
    "                    allophones.append(ph)\n",
    "\n",
    "        # Формируем input и target\n",
    "        input_text = f\"{original} {' '.join(letters)}\"\n",
    "        target_text = \" \".join(allophones)\n",
    "\n",
    "        data.append({\"input\": input_text, \"target\": target_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb27428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'товарищей т о в а р и щ е й', 'target': \"t a1 v a0 r' i4 sc i4 j\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b647dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60bc3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data: List[Dict], tokenizer, max_input_length=128, max_target_length=128):\n",
    "\n",
    "    def preprocess_function(samples):\n",
    "        # Добавляем префикс для task-specific обучения\n",
    "        inputs = [\"grapheme to phoneme: \" + i for i in samples[\"input\"]]\n",
    "        targets = samples[\"target\"]\n",
    "        \n",
    "        # Токенизация входных текстов\n",
    "        model_inputs = tokenizer(\n",
    "            inputs,\n",
    "            max_length=max_input_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        \n",
    "        # Токенизация таргетов\n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            max_length=max_target_length,\n",
    "            truncation=True,\n",
    "            padding=False\n",
    "        )\n",
    "        \n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "    \n",
    "\n",
    "    inputs = [sample[\"input\"] for sample in data]\n",
    "    targets = [sample[\"target\"] for sample in data]\n",
    "    \n",
    "    dataset_dict = {\n",
    "        \"input\": inputs,\n",
    "        \"target\": targets\n",
    "    }\n",
    "    \n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    tokenized_dataset = dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names\n",
    "    )\n",
    "    \n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b41ace1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70329cc3566a4f9f85ca905ce1f2f7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24844 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e13395466a47a7a52e51dc8dbefd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.1 , random_state=42)\n",
    "\n",
    "train_dataset = prepare_dataset(train_data, tokenizer)\n",
    "val_dataset = prepare_dataset(val_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf318c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'скамейках с к а м е й к а х', 'target': \"s k a1 m' e0 j k a4 h\"},\n",
       " {'input': 'вообще в о о б щ е', 'target': 'v a2 a1 p sc e0'},\n",
       " {'input': 'опередил о п е р е д и л', 'target': \"a1 p' i1 r' i1 d' i0 l\"},\n",
       " {'input': 'пополудни. п о п о л у д н и',\n",
       "  'target': \"p a2 p a1 l u0 d' n' i4\"},\n",
       " {'input': 'знать з н а т ь', 'target': \"z n a0 d'\"},\n",
       " {'input': 'была б ы л а', 'target': 'b y1 l a0'},\n",
       " {'input': 'Буй б у й', 'target': 'b u0 j'},\n",
       " {'input': 'и и', 'target': 'i1'},\n",
       " {'input': 'июля и ю л я', 'target': \"i1 j u0 l' a4\"},\n",
       " {'input': 'за з а', 'target': 'z a2'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85db9e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 24844\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a0f2c7",
   "metadata": {},
   "source": [
    "## Обучение и тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2679c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred, tokenizer):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Trainer может вернуть отрицательное значение для игнорируемых токенов\n",
    "    # для корректности вычислений такие значения заменяются на pad_token_id\n",
    "    predictions = np.where(predictions < 0, tokenizer.pad_token_id, predictions)\n",
    "    labels = np.where(labels < 0, tokenizer.pad_token_id, labels)\n",
    "\n",
    "    # Обратное преобразование токенов строки\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # CER\n",
    "    cer_metric = evaluate.load(\"cer\")\n",
    "    cer = cer_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # Word accuracy\n",
    "    correct = sum(pred.strip() == label.strip() for pred, label in zip(decoded_preds, decoded_labels))\n",
    "    accuracy = correct / len(decoded_preds)\n",
    "\n",
    "    return {\"cer\": cer, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3e871b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lezchook\\AppData\\Local\\Temp\\ipykernel_7080\\3219799277.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"cer\",\n",
    "    greater_is_better=False,\n",
    "    fp16=False,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=lambda eval_pred: compute_metrics(eval_pred, tokenizer),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=6)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56801d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = \"./Allophone-model/checkpoint-21000\"\n",
    "\n",
    "trainer.train(resume_from_checkpoint=last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b04f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bcbc0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='173' max='173' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [173/173 02:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Error Rate: 0.0185\n",
      "Word Accuracy: 0.8732\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(val_dataset)\n",
    "\n",
    "print(f\"Character Error Rate: {results['eval_cer']:.4f}\")\n",
    "print(f\"Word Accuracy: {results['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "615cc654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_allophones(texts, model_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_path).to(device)\n",
    "  \n",
    "    input_text = [\"grapheme to phoneme: \" + text for text in texts]\n",
    "    inputs = tokenizer(input_text, max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=128, num_beams=5, early_stopping=True)\n",
    "    \n",
    "    prediction = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65eeb297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Больше\n",
      "b o0 l' sh y4\n",
      "------------------------------\n",
      "всего\n",
      "f s' i1 v o0\n",
      "------------------------------\n",
      "человек\n",
      "ch i1 l a1 v' e0 k\n"
     ]
    }
   ],
   "source": [
    "allophones = predict_allophones([\"Больше б о л ь ш е\", \"всего в с е г о\", \"человек ч е л о в е к\"], \"./Allophone-model\")\n",
    "\n",
    "print(\"Больше\")\n",
    "print(allophones[0])\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\"всего\")\n",
    "print(allophones[1])\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\"человек\")\n",
    "print(allophones[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc605391",
   "metadata": {},
   "source": [
    "## Предсказание аллофонов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bea9b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_test_path  = \"./Example_Input_Phonetics.xml\"\n",
    "\n",
    "tree = ET.parse(XML_test_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "data = []\n",
    "\n",
    "for sentence in root.findall(\".//sentence\"):\n",
    "    for word in sentence.findall(\".//word\"):\n",
    "        original = word.get(\"original\")\n",
    "        letters = []\n",
    "\n",
    "        # Собираем буквы\n",
    "        for elem in word:\n",
    "            if elem.tag == \"letter\":\n",
    "                char = elem.get(\"char\")\n",
    "                if char:\n",
    "                    letters.append(char)\n",
    "\n",
    "        # Формируем input\n",
    "        input_text = f\"{original} {' '.join(letters)}\"\n",
    "        data.append(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc0dd30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# Побатчевое предсказание аллофонов\n",
    "\n",
    "batch_size = 64\n",
    "allophones = []\n",
    "\n",
    "steps = math.ceil(len(data) / batch_size)\n",
    "\n",
    "for i in tqdm(range(steps)):\n",
    "    batch = data[i * batch_size:i * batch_size + batch_size]\n",
    "    allophones.extend(predict_allophones(batch, \"./Allophone-model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "139acd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Больше б о л ь ш е',\n",
       " 'всего в с е г о',\n",
       " 'человек ч е л о в е к',\n",
       " 'ненавидит н е н а в и д и т',\n",
       " 'тех, т е х',\n",
       " 'кто к т о',\n",
       " 'смеется с м е ё т с я',\n",
       " 'ему е м у',\n",
       " 'прямо п р я м о',\n",
       " 'в в',\n",
       " 'глаза, г л а з а',\n",
       " 'а а',\n",
       " 'не н е',\n",
       " 'тех, т е х',\n",
       " 'кто к т о',\n",
       " 'смеется с м е ё т с я',\n",
       " 'за з а',\n",
       " 'его е г о',\n",
       " 'спиной. с п и н о й']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47fdf13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"b o0 l' sh y4\",\n",
       " \"f s' i1 v o0\",\n",
       " \"ch i1 l a1 v' e0 k\",\n",
       " \"n' i1 n a1 v' i0 d' i4 t\",\n",
       " \"t' e0 h\",\n",
       " 'k t o0',\n",
       " \"s m' i1 j o0 c a4\",\n",
       " 'j i1 m u0',\n",
       " \"p r' a0 m a4\",\n",
       " 'v',\n",
       " 'g l a1 z a0',\n",
       " 'a1',\n",
       " \"n' i1\",\n",
       " \"t' e0 h\",\n",
       " 'k t o0',\n",
       " \"s m' i1 j o0 c a4\",\n",
       " 'z a2',\n",
       " 'j i1 v o0',\n",
       " \"s p' i1 n o0 j\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allophones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ec58bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение результатов в JSON файл\n",
    "\n",
    "output = [{\n",
    "    \"words\": [\n",
    "        {\n",
    "            \"content\": input_text.split()[0],\n",
    "            \"allophones\": output_text.split()\n",
    "        }\n",
    "        for input_text, output_text in zip(data, allophones)\n",
    "    ]\n",
    "}]\n",
    "\n",
    "with open(\"leshchenko_phonetics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68914ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
